{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88cad664-afa2-4849-ac28-fad1ee28d89e",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59df8c7a-b8bd-480d-837f-c2dbecf533dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sea\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb7617d-01ab-43eb-8b43-672067672160",
   "metadata": {},
   "source": [
    "# Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674b0b21-c3ff-412e-89ee-9c81cb391a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'dataset'\n",
    "\n",
    "# creating lists of filenames and disease outcome of each image\n",
    "filenames, outcome = [], []\n",
    "for label in os.listdir(path):\n",
    "    for img in os.listdir(os.path.join(path,label)):\n",
    "        filenames.append(os.path.join(path,label,img));\n",
    "        outcome.append(label)\n",
    "\n",
    "for i in range(len(filenames)):\n",
    "    print(f'{filenames[i]} : {outcome[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4704d5a8-8356-48b2-84dc-8b3b65404c46",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37089ef-7ef2-4d29-ae2e-976048e870d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists for images and labels\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Define a consistent size for all images (e.g., 224x224 pixels)\n",
    "image_size = (256, 256)\n",
    "\n",
    "# Mapping outcomes to numerical labels\n",
    "outcome_to_label = {\n",
    "    \"cataract\": 0,\n",
    "    \"diabetic_retinopathy\": 1,\n",
    "    \"glaucoma\": 2,\n",
    "    \"other\": 3  \n",
    "}\n",
    "\n",
    "# Convert images to numpy arrays and create labels\n",
    "for i in range(len(filenames)):\n",
    "    # Open image\n",
    "    image = Image.open(filenames[i])\n",
    "    # Convert image to RGB if not already\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')\n",
    "    # Resize image to the defined size\n",
    "    image = image.resize(image_size)\n",
    "    # Convert image to numpy array\n",
    "    X.append(np.array(image))\n",
    "    # Append corresponding label\n",
    "    y.append(outcome_to_label.get(outcome[i], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84b1e11-f6ad-4a09-8f18-967488c647bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conveting X and y in numpy array\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b473c5-0a83-4d9d-a5f6-e593b6d5745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1be6d4-d4f4-40ad-8e67-5b3c84647405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e20069-86f7-474b-a1c2-17dadb2faa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71fe455-b6ab-4652-a1a6-64e71d6057f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880ff526-00ef-4779-9af7-965aef19b8cf",
   "metadata": {},
   "source": [
    "# Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9259709b-bc7f-40aa-870e-2d7e52c7d756",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10052bf2-b77d-408c-8b5d-9ad38f56ff67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, models, layers\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51ab179-cffd-4aa2-93a7-e8d30b7c9d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "convolutional_base = ResNet50(weights = 'imagenet', include_top = False, input_shape = (256,256,3))\n",
    "convolutional_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d864626-4a99-4416-ac14-d763737236d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "model = models.Sequential()\n",
    "model.add(convolutional_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e918745-63aa-48f0-9c4a-49c97937c371",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a184db06-c262-47de-8018-7b954495fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, validation_split=0.15, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145a70c4-0815-4686-b42d-594828f14902",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test Accuarcy = ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15aee2df-d99b-4599-a3d1-4e11102593d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss value\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot the accuracy value\n",
    "plt.plot(history.history['acc'], label='train accuracy')\n",
    "plt.plot(history.history['val_acc'], label='validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53debcff-46da-411a-b06a-92ea4c5204cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
